<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.111.0">
<title>Understanding Confusion Matrix | Outlier Blog</title>








  
    
  
<meta name="description" content="When working with machine learning models, it is essential to evaluate their performance to determine if they are making accurate predictions. One of the most popular methods of evaluating the performance of a model is by using a confusion matrix.">


<meta property="og:site_name" content="Outlier Blog">
<meta property="og:title" content="Understanding Confusion Matrix | Outlier Blog">
<meta property="og:description" content="When working with machine learning models, it is essential to evaluate their performance to determine if they are making accurate predictions. One of the most popular methods of evaluating the performance of a model is by using a confusion matrix." />
<meta property="og:type" content="page" />
<meta property="og:url" content="/blog/2023-03-02-understanding-confusion-matrix/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="/blog/2023-03-02-understanding-confusion-matrix/featured.jpg" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="/blog/2023-03-02-understanding-confusion-matrix/featured.jpg" >
    
    
  <meta itemprop="name" content="Understanding Confusion Matrix">
<meta itemprop="description" content="When working with machine learning models, it is essential to evaluate their performance to determine if they are making accurate predictions. One of the most popular methods of evaluating the performance of a model is by using a confusion matrix. A confusion matrix is a table that is used to evaluate the accuracy of a classification model.
What is a Confusion Matrix? A confusion matrix is an essential tool used to evaluate the performance of a classification model."><meta itemprop="datePublished" content="2023-03-02T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-03-02T00:00:00+00:00" />
<meta itemprop="wordCount" content="962"><meta itemprop="image" content="/blog/2023-03-02-understanding-confusion-matrix/featured.jpg">
<meta itemprop="keywords" content="" />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.51ef9a26ed5e31959c31ea456a050c05fbf3938c97c284a4438715138fcb2e8d.css" integrity="sha256-Ue&#43;aJu1eMZWcMepFagUMBfvzk4yXwoSkQ4cVE4/LLo0=" media="screen">
  
  
  <script src="/panelset.min.ed1ac24b6e16f4e2481e3d1d098ae66f5bc77438aef619e6e266d8ac5b00dc72.js" type="text/javascript"></script>
  
  
  <script src="/main.min.649b37902a58940ccb0994180039a0295d71785e8ede8221f0c9fb5bf73c9354.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container single">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="/" title="Home">
      <img src="/img/logo.png" class="dib db-l h2 w-auto" alt="Outlier Blog">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About Me">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Understanding Confusion Matrix</h1>
        
        <p class="f6 measure lh-copy mv1">By Thomas Shaw in <a href="/categories/python">python</a>  <a href="/categories/classification">classification</a> </p>
        <p class="f7 db mv0 ttu">March 2, 2023</p>

      

      </header>
      <section class="post-body pt5 pb4">
        <p>When working with machine learning models, it is essential to evaluate their performance to determine if they are making accurate predictions. One of the most popular methods of evaluating the performance of a model is by using a confusion matrix. A confusion matrix is a table that is used to evaluate the accuracy of a classification model.</p>




<h2 id="what-is-a-confusion-matrix">What is a Confusion Matrix?
  <a href="#what-is-a-confusion-matrix"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>A confusion matrix is an essential tool used to evaluate the performance of a classification model. In classification problems, simply measuring accuracy may not be enough, especially if the classes are imbalanced. Therefore, a confusion matrix can give us a more detailed and informative summary of a model’s performance.</p>
<p>The confusion matrix is constructed by using four different values: true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). These values represent the number of times that the model correctly or incorrectly predicted the positive or negative class.</p>
<p>True positives (TP) are the number of correct predictions that the model made for the positive class. False positives (FP) are the number of incorrect predictions that the model made for the positive class. True negatives (TN) are the number of correct predictions that the model made for the negative class, and false negatives (FN) are the number of incorrect predictions that the model made for the negative class.</p>
<p>Imagine a doctor trying to diagnose a patient for a disease. The patient either has the disease (positive) or doesn’t have it (negative), and the doctor’s diagnosis can either be right or wrong.</p>
<ul>
<li>True Positive (TP): The doctor correctly diagnoses the patient with the disease when the patient actually has it.</li>
<li>False Positive (FP): The doctor diagnoses the patient with the disease when the patient does not have it.</li>
<li>True Negative (TN): The doctor correctly determines that the patient does not have the disease when the patient actually does not have it.</li>
<li>False Negative (FN): The doctor fails to diagnose the patient with the disease when the patient actually has it.</li>
</ul>
<p><img src="confusion_matrix.png" alt="Confusion matrix of the doctor’s diagnosis"></p>
<p><br></br></p>




<h2 id="how-to-interpret-a-confusion-matrix">How to Interpret a Confusion Matrix?
  <a href="#how-to-interpret-a-confusion-matrix"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>A confusion matrix provides valuable insights into the performance of a classification model. By analyzing the values in the matrix, we can determine the accuracy, precision, recall, and F1 score of the model.</p>




<h3 id="accuracy">Accuracy
  <a href="#accuracy"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>Accuracy is the most commonly used metric to evaluate the performance of a classification model. It is calculated by dividing the sum of true positives and true negatives by the total number of predictions made by the model. A high accuracy score indicates that the model is making correct predictions most of the time.</p>
<p><img src="accuracy.png" alt=""></p>




<h3 id="precision">Precision
  <a href="#precision"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>Precision is the ratio of true positives to the sum of true positives and false positives. It measures the proportion of positive predictions that were actually correct. A high precision score indicates that the model is making very few false positive predictions.</p>
<p><img src="precision.png" alt=""></p>




<h3 id="recall">Recall
  <a href="#recall"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>Recall is the ratio of true positives to the sum of true positives and false negatives. It measures the proportion of actual positives that were correctly identified by the model. A high recall score indicates that the model is correctly identifying positive instances.</p>
<p><img src="recall.png" alt=""></p>




<h3 id="f1-score">F1 Score
  <a href="#f1-score"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall, which makes it a better metric to evaluate the performance of a model when the dataset is imbalanced. A high F1 score indicates that the model is making both high precision and high recall predictions.</p>
<p><img src="score.png" alt=""></p>
<p><br></br></p>




<h2 id="benefits-of-using-confusion-matrix">Benefits of Using Confusion Matrix
  <a href="#benefits-of-using-confusion-matrix"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>




<h3 id="improved-accuracy-evaluation">Improved accuracy evaluation
  <a href="#improved-accuracy-evaluation"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>One of the primary advantages of a confusion matrix is that it provides a more detailed and nuanced evaluation of a model’s performance than just relying on overall accuracy. While overall accuracy can provide a general sense of how well a model is doing, a confusion matrix can reveal areas where the model may be struggling or performing exceptionally well.</p>




<h3 id="identification-of-model-strengths-and-weaknesses">Identification of model strengths and weaknesses
  <a href="#identification-of-model-strengths-and-weaknesses"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>By breaking down the results of a classification model into a confusion matrix, we can identify specific areas where the model is excelling or struggling. For example, a high true positive rate indicates that the model is correctly identifying positive instances, while a high false positive rate indicates that the model is incorrectly identifying negative instances as positive. By understanding the strengths and weaknesses of a model, we can make more informed decisions about how to improve its performance.</p>




<h3 id="selection-of-appropriate-evaluation-metrics">Selection of appropriate evaluation metrics
  <a href="#selection-of-appropriate-evaluation-metrics"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>The confusion matrix also allows us to calculate a variety of evaluation metrics, such as precision, recall, and F1-score. These metrics provide different perspectives on a model’s performance and can help us understand how well it is doing in different areas. For example, precision measures how many of the positive predictions were actually correct, while recall measures how many of the actual positive instances were correctly identified by the model.</p>




<h3 id="optimization-of-model-performance">Optimization of model performance
  <a href="#optimization-of-model-performance"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h3>
<p>Finally, the confusion matrix can help us make informed decisions about how to optimize a model’s performance. By analyzing the results of the confusion matrix, we can identify areas where the model may be struggling and take steps to address these issues. For example, if the model is producing a high number of false positives, we may need to adjust the classification threshold or improve the quality of the training data to reduce this error rate.</p>
<p><br></br></p>




<h2 id="conclusion">Conclusion
  <a href="#conclusion"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>A confusion matrix is an essential tool for evaluating the performance of a classification model. It provides a clear and concise way to determine the accuracy, precision, recall, and F1 score of a model. By analyzing the values in the matrix, we can determine the strengths and weaknesses of the model and make necessary adjustments to improve its performance. Machine learning practitioners should be familiar with the confusion matrix and utilize it as a primary tool to evaluate the performance of their classification models.</p>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">March 2, 2023</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">5 minute read, 962 words</dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Categories:</dt>
    <dd class="fw5 ml0"> <a href="/categories/python">python</a>  <a href="/categories/classification">classification</a> </dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="/blog/2023-03-08-understanding-the-importance-of-model-explainability-in-machine-learning/">&larr; Understanding the Importance of Model Explainability in Machine Learning</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="/blog/2023-02-21-addressing-class-imbalance-in-classification/">Addressing Class Imbalance in Classification &rarr;</a>
  
</div>

      </footer>
    </article>
    
  </section>
  	<div class="relative flex py-5 items-center">
	</div>
	<div class="flex justify-center">
		<p style="margin-bottom: 1em;"><b>Support my work with a cup of ☕</b></p>
	</div>
	<div class="flex justify-center">
		<script type='text/javascript' src='https://storage.ko-fi.com/cdn/widget/Widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Donate', '#4c7021', 'N4N1EM0G5');kofiwidget2.draw();</script>
	</div>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2023 Thomas Shaw
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/thomassshaw" title="github" target="_blank" rel="me noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://medium.com/@thomassshaw" title="medium" target="_blank" rel="me noopener">
      <i class="fab fa-medium fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="/blog/index.xml" title="rss" >
      <i class="fas fa-rss fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/contact/" title="Contact form">Contact</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
